#!/usr/bin/env python3
"""
MongoDB ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜ ìŠ¤í¬ë¦½íŠ¸ v2.0
CREATED [2024-12-19]: ê¸°ì¡´ ì»¬ë ‰ì…˜ êµ¬ì¡°ë¥¼ ìƒˆë¡œìš´ êµ¬ì¡°ë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜

ë§ˆì´ê·¸ë ˆì´ì…˜ ë‚´ìš©:
- chunks â†’ Document (folder_id ì¶”ê°€, í•„ë“œëª… ë³€ê²½)
- labels â†’ Labels (êµ¬ì¡° í‰íƒ„í™”, folder_id ì¶”ê°€)
- qa_pairs â†’ QAPairs (ë°°ì—´ì„ ê°œë³„ ë¬¸ì„œë¡œ ë¶„ë¦¬)
- ì‹ ê·œ Folder ì»¬ë ‰ì…˜ ìƒì„±
"""

import sys
import os
sys.path.append('.')

from pymongo import MongoClient
from datetime import datetime, timezone
from typing import Dict, Any, List, Optional
import json
import logging
from bson import ObjectId
from config.settings import settings
from src.utils.schemas import MongoSchemas

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class DatabaseMigration:
    def __init__(self, mongodb_uri: str):
        """ë§ˆì´ê·¸ë ˆì´ì…˜ í´ë˜ìŠ¤ ì´ˆê¸°í™”"""
        self.client = MongoClient(mongodb_uri)
        self.db = self.client.rag_system
        
        # ê¸°ì¡´ ì»¬ë ‰ì…˜
        self.old_chunks = self.db.chunks
        self.old_labels = self.db.labels
        self.old_qa_pairs = self.db.qa_pairs
        
        # ìƒˆ ì»¬ë ‰ì…˜
        self.new_documents = self.db.Document
        self.new_labels = self.db.Labels
        self.new_qa_pairs = self.db.QAPairs
        self.new_folders = self.db.Folder
        
        # ê¸°ë³¸ í´ë” ID (ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œ ìƒì„±)
        self.default_folder_id = None
        
    def backup_existing_data(self, backup_path: str = "./data/backup"):
        """ê¸°ì¡´ ë°ì´í„° ë°±ì—…"""
        logger.info("ğŸ”„ ê¸°ì¡´ ë°ì´í„° ë°±ì—… ì‹œì‘...")
        
        os.makedirs(backup_path, exist_ok=True)
        
        # ê° ì»¬ë ‰ì…˜ ë°±ì—…
        collections = {
            'chunks': self.old_chunks,
            'labels': self.old_labels,
            'qa_pairs': self.old_qa_pairs
        }
        
        for name, collection in collections.items():
            data = list(collection.find())
            backup_file = os.path.join(backup_path, f"{name}_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json")
            
            # ObjectIdë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
            for doc in data:
                if '_id' in doc:
                    doc['_id'] = str(doc['_id'])
            
            with open(backup_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2, default=str)
            
            logger.info(f"âœ… {name} ë°±ì—… ì™„ë£Œ: {backup_file} ({len(data)}ê°œ ë¬¸ì„œ)")
        
        logger.info("âœ… ëª¨ë“  ë°ì´í„° ë°±ì—… ì™„ë£Œ")
    
    def create_default_folder(self) -> ObjectId:
        """ê¸°ë³¸ í´ë” ìƒì„±"""
        logger.info("ğŸ“ ê¸°ë³¸ í´ë” ìƒì„±...")
        
        default_folder = {
            "title": "ê¸°ë³¸ í´ë”",
            "description": "ë§ˆì´ê·¸ë ˆì´ì…˜ìœ¼ë¡œ ìƒì„±ëœ ê¸°ë³¸ ì»¨í…Œì´ë„ˆ í´ë”",
            "folder_type": "general",
            "parent_folder_id": None,
            "created_at": datetime.now(timezone.utc),
            "last_accessed_at": datetime.now(timezone.utc),
            "cover_image_url": None,
            "metadata": {
                "migration_created": True,
                "migration_date": datetime.now(timezone.utc).isoformat()
            }
        }
        
        result = self.new_folders.insert_one(default_folder)
        self.default_folder_id = result.inserted_id
        
        logger.info(f"âœ… ê¸°ë³¸ í´ë” ìƒì„± ì™„ë£Œ: {self.default_folder_id}")
        return self.default_folder_id
    
    def migrate_chunks_to_documents(self):
        """chunks â†’ Document ë§ˆì´ê·¸ë ˆì´ì…˜"""
        logger.info("ğŸ”„ chunks â†’ Document ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œì‘...")
        
        chunks = list(self.old_chunks.find())
        logger.info(f"ğŸ“Š ì²˜ë¦¬í•  chunks: {len(chunks)}ê°œ")
        
        migrated_count = 0
        chunk_id_mapping = {}  # ê¸°ì¡´ chunk_idì™€ ìƒˆ document ObjectId ë§¤í•‘
        
        for chunk in chunks:
            try:
                # ìƒˆ Document ë°ì´í„° êµ¬ì¡°
                new_document = {
                    "folder_id": self.default_folder_id,
                    "chunk_sequence": chunk.get("chunk_id", f"chunk_{migrated_count}"),
                    "raw_text": chunk.get("content", ""),
                    "text_embedding": [],  # ì„ì‹œë¡œ ë¹ˆ ë°°ì—´ (ë‚˜ì¤‘ì— ë²¡í„° ì´ê´€)
                    "metadata": chunk.get("metadata", {}),
                    "created_at": chunk.get("created_at", datetime.now(timezone.utc)),
                    "updated_at": datetime.now(timezone.utc)
                }
                
                # ë©”íƒ€ë°ì´í„°ì— ì›ë³¸ ì •ë³´ ì¶”ê°€
                new_document["metadata"]["original_chunk_id"] = chunk.get("chunk_id")
                new_document["metadata"]["migrated_from"] = "chunks"
                
                # ìƒˆ Document ì‚½ì…
                result = self.new_documents.insert_one(new_document)
                
                # ID ë§¤í•‘ ì €ì¥ (ë‚˜ì¤‘ì— Labels, QAPairs ë§ˆì´ê·¸ë ˆì´ì…˜ì—ì„œ ì‚¬ìš©)
                original_chunk_id = chunk.get("chunk_id")
                if original_chunk_id:
                    chunk_id_mapping[original_chunk_id] = result.inserted_id
                
                migrated_count += 1
                
                if migrated_count % 100 == 0:
                    logger.info(f"ì§„í–‰ ìƒí™©: {migrated_count}/{len(chunks)} chunks ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ")
                    
            except Exception as e:
                logger.error(f"âŒ chunk ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨: {chunk.get('_id', 'unknown')} - {str(e)}")
        
        logger.info(f"âœ… chunks â†’ Document ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ: {migrated_count}ê°œ")
        return chunk_id_mapping
    
    def migrate_labels(self, chunk_id_mapping: Dict[str, ObjectId]):
        """labels â†’ Labels ë§ˆì´ê·¸ë ˆì´ì…˜"""
        logger.info("ğŸ”„ labels â†’ Labels ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œì‘...")
        
        labels = list(self.old_labels.find())
        logger.info(f"ğŸ“Š ì²˜ë¦¬í•  labels: {len(labels)}ê°œ")
        
        migrated_count = 0
        
        for label in labels:
            try:
                # ê¸°ì¡´ chunk_idë¡œ ìƒˆ document_id ì°¾ê¸°
                original_chunk_id = label.get("chunk_id")
                document_id = chunk_id_mapping.get(original_chunk_id)
                
                if not document_id:
                    logger.warning(f"âš ï¸ chunk_id '{original_chunk_id}'ì— í•´ë‹¹í•˜ëŠ” Documentë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                    continue
                
                # ë¼ë²¨ ë°ì´í„° êµ¬ì¡° í‰íƒ„í™”
                labels_data = label.get("labels", {})
                
                new_label = {
                    "document_id": document_id,
                    "folder_id": self.default_folder_id,
                    "main_topic": labels_data.get("main_topic", ""),
                    "tags": labels_data.get("tags", []),
                    "category": labels_data.get("category", "general"),
                    "confidence": 0.8,  # ê¸°ë³¸ ì‹ ë¢°ë„
                    "created_at": label.get("created_at", datetime.now(timezone.utc)),
                    "updated_at": datetime.now(timezone.utc)
                }
                
                # ìƒˆ Labels ì‚½ì…
                self.new_labels.insert_one(new_label)
                migrated_count += 1
                
                if migrated_count % 50 == 0:
                    logger.info(f"ì§„í–‰ ìƒí™©: {migrated_count}/{len(labels)} labels ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ")
                    
            except Exception as e:
                logger.error(f"âŒ label ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨: {label.get('_id', 'unknown')} - {str(e)}")
        
        logger.info(f"âœ… labels â†’ Labels ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ: {migrated_count}ê°œ")
    
    def migrate_qa_pairs(self, chunk_id_mapping: Dict[str, ObjectId]):
        """qa_pairs â†’ QAPairs ë§ˆì´ê·¸ë ˆì´ì…˜ (ë°°ì—´ì„ ê°œë³„ ë¬¸ì„œë¡œ ë¶„ë¦¬)"""
        logger.info("ğŸ”„ qa_pairs â†’ QAPairs ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œì‘...")
        
        qa_records = list(self.old_qa_pairs.find())
        logger.info(f"ğŸ“Š ì²˜ë¦¬í•  qa_pairs ë ˆì½”ë“œ: {len(qa_records)}ê°œ")
        
        migrated_count = 0
        total_qa_pairs = 0
        
        for qa_record in qa_records:
            try:
                # ê¸°ì¡´ chunk_idë¡œ ìƒˆ document_id ì°¾ê¸°
                original_chunk_id = qa_record.get("chunk_id")
                document_id = chunk_id_mapping.get(original_chunk_id)
                
                if not document_id:
                    logger.warning(f"âš ï¸ chunk_id '{original_chunk_id}'ì— í•´ë‹¹í•˜ëŠ” Documentë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                    continue
                
                # qa_pairs ë°°ì—´ì—ì„œ ê° QAë¥¼ ê°œë³„ ë¬¸ì„œë¡œ ë¶„ë¦¬
                qa_pairs = qa_record.get("qa_pairs", [])
                
                for qa_pair in qa_pairs:
                    if isinstance(qa_pair, dict) and "question" in qa_pair and "answer" in qa_pair:
                        new_qa = {
                            "document_id": document_id,
                            "folder_id": self.default_folder_id,
                            "question": qa_pair["question"],
                            "answer": qa_pair["answer"],
                            "question_type": self._classify_question_type(qa_pair["question"]),
                            "difficulty": "medium",  # ê¸°ë³¸ ë‚œì´ë„
                            "created_at": qa_record.get("created_at", datetime.now(timezone.utc)),
                            "updated_at": datetime.now(timezone.utc)
                        }
                        
                        # ìƒˆ QAPairs ì‚½ì…
                        self.new_qa_pairs.insert_one(new_qa)
                        total_qa_pairs += 1
                
                migrated_count += 1
                
                if migrated_count % 10 == 0:
                    logger.info(f"ì§„í–‰ ìƒí™©: {migrated_count}/{len(qa_records)} qa_records ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ")
                    
            except Exception as e:
                logger.error(f"âŒ qa_pairs ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨: {qa_record.get('_id', 'unknown')} - {str(e)}")
        
        logger.info(f"âœ… qa_pairs â†’ QAPairs ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ: {total_qa_pairs}ê°œ QA ìŒ")
    
    def _classify_question_type(self, question: str) -> str:
        """ì§ˆë¬¸ ìœ í˜• ë¶„ë¥˜"""
        question_lower = question.lower()
        
        if any(word in question_lower for word in ["what", "ë¬´ì—‡", "ë­"]):
            return "what"
        elif any(word in question_lower for word in ["how", "ì–´ë–»ê²Œ", "ë°©ë²•"]):
            return "how"
        elif any(word in question_lower for word in ["why", "ì™œ", "ì´ìœ "]):
            return "why"
        elif any(word in question_lower for word in ["when", "ì–¸ì œ", "ì‹œê¸°"]):
            return "when"
        elif any(word in question_lower for word in ["where", "ì–´ë””", "ì¥ì†Œ"]):
            return "where"
        elif any(word in question_lower for word in ["who", "ëˆ„êµ¬", "ëˆ„ê°€"]):
            return "who"
        else:
            return "general"
    
    def create_indexes(self):
        """ìƒˆ ì»¬ë ‰ì…˜ì— ì¸ë±ìŠ¤ ìƒì„±"""
        logger.info("ğŸ” ì¸ë±ìŠ¤ ìƒì„± ì‹œì‘...")
        
        schemas = MongoSchemas()
        indexes = schemas.get_indexes()
        
        for collection_name, index_list in indexes.items():
            collection = getattr(self, f"new_{collection_name.lower()}", None)
            if collection is None:
                if collection_name == "Document":
                    collection = self.new_documents
                elif collection_name == "Labels":
                    collection = self.new_labels
                elif collection_name == "QAPairs":
                    collection = self.new_qa_pairs
                elif collection_name == "Folder":
                    collection = self.new_folders
            
            if collection is not None:
                for index_spec in index_list:
                    try:
                        if isinstance(index_spec, tuple) and len(index_spec) == 2:
                            collection.create_index(index_spec)
                        elif isinstance(index_spec, list):
                            collection.create_index(index_spec)
                        logger.info(f"âœ… {collection_name} ì¸ë±ìŠ¤ ìƒì„±: {index_spec}")
                    except Exception as e:
                        logger.warning(f"âš ï¸ {collection_name} ì¸ë±ìŠ¤ ìƒì„± ì‹¤íŒ¨: {index_spec} - {str(e)}")
        
        logger.info("âœ… ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ")
    
    def verify_migration(self) -> Dict[str, Any]:
        """ë§ˆì´ê·¸ë ˆì´ì…˜ ê²°ê³¼ ê²€ì¦"""
        logger.info("ğŸ” ë§ˆì´ê·¸ë ˆì´ì…˜ ê²°ê³¼ ê²€ì¦ ì‹œì‘...")
        
        verification_result = {
            "original_counts": {
                "chunks": self.old_chunks.count_documents({}),
                "labels": self.old_labels.count_documents({}),
                "qa_pairs": self.old_qa_pairs.count_documents({})
            },
            "new_counts": {
                "Document": self.new_documents.count_documents({}),
                "Labels": self.new_labels.count_documents({}),
                "QAPairs": self.new_qa_pairs.count_documents({}),
                "Folder": self.new_folders.count_documents({})
            },
            "default_folder_id": str(self.default_folder_id),
            "migration_timestamp": datetime.now(timezone.utc).isoformat()
        }
        
        # ê²€ì¦ ê²°ê³¼ ì¶œë ¥
        logger.info("ğŸ“Š ë§ˆì´ê·¸ë ˆì´ì…˜ ê²°ê³¼:")
        logger.info(f"   - ê¸°ì¡´ chunks: {verification_result['original_counts']['chunks']}ê°œ")
        logger.info(f"   - ìƒˆ Document: {verification_result['new_counts']['Document']}ê°œ")
        logger.info(f"   - ê¸°ì¡´ labels: {verification_result['original_counts']['labels']}ê°œ")
        logger.info(f"   - ìƒˆ Labels: {verification_result['new_counts']['Labels']}ê°œ")
        logger.info(f"   - ê¸°ì¡´ qa_pairs: {verification_result['original_counts']['qa_pairs']}ê°œ")
        logger.info(f"   - ìƒˆ QAPairs: {verification_result['new_counts']['QAPairs']}ê°œ")
        logger.info(f"   - ìƒˆ Folder: {verification_result['new_counts']['Folder']}ê°œ")
        
        return verification_result
    
    def run_migration(self, backup: bool = True):
        """ì „ì²´ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰"""
        logger.info("ğŸš€ MongoDB ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œì‘")
        logger.info("=" * 50)
        
        try:
            # 1. ë°±ì—…
            if backup:
                self.backup_existing_data()
            
            # 2. ê¸°ë³¸ í´ë” ìƒì„±
            self.create_default_folder()
            
            # 3. chunks â†’ Document ë§ˆì´ê·¸ë ˆì´ì…˜
            chunk_id_mapping = self.migrate_chunks_to_documents()
            
            # 4. labels â†’ Labels ë§ˆì´ê·¸ë ˆì´ì…˜
            self.migrate_labels(chunk_id_mapping)
            
            # 5. qa_pairs â†’ QAPairs ë§ˆì´ê·¸ë ˆì´ì…˜
            self.migrate_qa_pairs(chunk_id_mapping)
            
            # 6. ì¸ë±ìŠ¤ ìƒì„±
            self.create_indexes()
            
            # 7. ê²€ì¦
            verification_result = self.verify_migration()
            
            logger.info("=" * 50)
            logger.info("ğŸ‰ ë§ˆì´ê·¸ë ˆì´ì…˜ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œ!")
            
            return verification_result
            
        except Exception as e:
            logger.error(f"âŒ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨: {str(e)}")
            raise
        finally:
            self.client.close()

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    import argparse
    
    parser = argparse.ArgumentParser(description="MongoDB ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜")
    parser.add_argument("--no-backup", action="store_true", help="ë°±ì—… ìƒì„± ê±´ë„ˆë›°ê¸°")
    parser.add_argument("--mongodb-uri", default=settings.mongodb_uri, help="MongoDB URI")
    
    args = parser.parse_args()
    
    # ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰
    migration = DatabaseMigration(args.mongodb_uri)
    result = migration.run_migration(backup=not args.no_backup)
    
    # ê²°ê³¼ ì €ì¥
    with open("./data/migration_result.json", "w", encoding="utf-8") as f:
        json.dump(result, f, ensure_ascii=False, indent=2, default=str)
    
    print("\nğŸ“„ ë§ˆì´ê·¸ë ˆì´ì…˜ ê²°ê³¼ê°€ ./data/migration_result.jsonì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main() 